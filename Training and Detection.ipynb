{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eba34298",
   "metadata": {},
   "source": [
    "Remember that the labels that we are using are: `tongueout`, `wink`, `smile`, `surprise`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eae869e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df067e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04c1862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8213fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea4d6427",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a724fda",
   "metadata": {},
   "source": [
    "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f93b95",
   "metadata": {},
   "source": [
    "Let's start clonning the TFOD API on `'Tensorflow/models/research/object_detection'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be37bbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clonando en 'Tensorflow/models'...\n",
      "remote: Enumerating objects: 65274, done.\u001b[K\n",
      "remote: Counting objects: 100% (274/274), done.\u001b[K\n",
      "remote: Compressing objects: 100% (264/264), done.\u001b[K\n",
      "remote: Total 65274 (delta 143), reused 139 (delta 10), pack-reused 65000\u001b[K\n",
      "Recibiendo objetos: 100% (65274/65274), 575.48 MiB | 12.60 MiB/s, listo.\n",
      "Resolviendo deltas: 100% (45676/45676), listo.\n",
      "Actualizando archivos: 100% (2766/2766), listo.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c57315",
   "metadata": {},
   "source": [
    "Let's install the protocol buffer compiler, `protoc`, used to compile *.proto* files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0354469d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Homebrew...\n",
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updated Homebrew!\u001b[0m\n",
      "Updated 2 taps (homebrew/core and homebrew/cask).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mUpdated Formulae\u001b[0m\n",
      "Updated 23 formulae.\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNew Casks\u001b[0m\n",
      "hydrus-network                           sqlcl\n",
      "\u001b[34m==>\u001b[0m \u001b[1mUpdated Casks\u001b[0m\n",
      "Updated 36 casks.\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDeleted Casks\u001b[0m\n",
      "spectx\n",
      "\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/six/manifests/1.16.0_2-1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/six/blobs/sha256:560f73cafaea61\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/protobuf/manifests/3.17.3\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/protobuf/blobs/sha256:d1060a6f7\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling dependencies for protobuf: \u001b[32msix\u001b[39m\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling protobuf dependency: \u001b[32msix\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring six--1.16.0_2.all.bottle.1.tar.gz\u001b[0m\n",
      "🍺  /usr/local/Cellar/six/1.16.0_2: 20 files, 122.3KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling \u001b[32mprotobuf\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring protobuf--3.17.3.big_sur.bottle.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mCaveats\u001b[0m\n",
      "Emacs Lisp files have been installed to:\n",
      "  /usr/local/share/emacs/site-lisp/protobuf\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSummary\u001b[0m\n",
      "🍺  /usr/local/Cellar/protobuf/3.17.3: 210 files, 18.0MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mCaveats\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mprotobuf\u001b[0m\n",
      "Emacs Lisp files have been installed to:\n",
      "  /usr/local/share/emacs/site-lisp/protobuf\n",
      "Processing /Users/jaime/deep_learning/object_detection_tf/Tensorflow/models/research\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting avro-python3\n",
      "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting apache-beam\n",
      "  Downloading apache_beam-2.33.0-cp38-cp38-macosx_10_9_x86_64.whl (4.2 MB)\n",
      "     |████████████████████████████████| 4.2 MB 4.0 MB/s            \n",
      "\u001b[?25hCollecting pillow\n",
      "  Downloading Pillow-8.4.0-cp38-cp38-macosx_10_10_x86_64.whl (3.0 MB)\n",
      "     |████████████████████████████████| 3.0 MB 56.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: lxml in /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages (from object-detection==0.1) (4.6.3)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.4.3-cp38-cp38-macosx_10_9_x86_64.whl (7.2 MB)\n",
      "Collecting Cython\n",
      "  Downloading Cython-0.29.24-cp38-cp38-macosx_10_9_x86_64.whl (1.9 MB)\n",
      "     |████████████████████████████████| 1.9 MB 46.9 MB/s            \n",
      "\u001b[?25hCollecting contextlib2\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting tf-slim\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "     |████████████████████████████████| 352 kB 7.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: six in /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages (from object-detection==0.1) (1.16.0)\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lvis\n",
      "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.7.1-cp38-cp38-macosx_10_9_x86_64.whl (32.6 MB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.3.4-cp38-cp38-macosx_10_9_x86_64.whl (11.4 MB)\n",
      "     |████████████████████████████████| 11.4 MB 9.1 MB/s            \n",
      "\u001b[?25hCollecting tf-models-official>=2.5.1\n",
      "  Downloading tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n",
      "     |████████████████████████████████| 1.8 MB 7.4 MB/s            \n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp38-cp38-macosx_10_9_x86_64.whl (192 kB)\n",
      "     |████████████████████████████████| 192 kB 9.4 MB/s            \n",
      "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
      "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "     |████████████████████████████████| 99 kB 2.0 MB/s             \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.14.0-cp38-cp38-macosx_10_13_x86_64.whl (575 kB)\n",
      "     |████████████████████████████████| 575 kB 11.1 MB/s            \n",
      "\u001b[?25hCollecting psutil>=5.4.3\n",
      "  Downloading psutil-5.8.0-cp38-cp38-macosx_10_9_x86_64.whl (236 kB)\n",
      "     |████████████████████████████████| 236 kB 11.5 MB/s            \n",
      "\u001b[?25hCollecting gin-config\n",
      "  Downloading gin_config-0.4.0-py2.py3-none-any.whl (46 kB)\n",
      "     |████████████████████████████████| 46 kB 6.3 MB/s             \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-macosx_10_6_x86_64.whl (1.1 MB)\n",
      "     |████████████████████████████████| 1.1 MB 9.1 MB/s            \n",
      "\u001b[?25hCollecting kaggle>=1.3.9\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "     |████████████████████████████████| 58 kB 6.5 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow>=2.5.0\n",
      "  Using cached tensorflow-2.6.0-cp38-cp38-macosx_10_11_x86_64.whl (199.0 MB)\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.4.58-cp38-cp38-macosx_10_15_x86_64.whl (45.5 MB)\n",
      "     |████████████████████████████████| 45.5 MB 13.2 MB/s            \n",
      "\u001b[?25hCollecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "     |████████████████████████████████| 43 kB 6.0 MB/s             \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.4.0-py3-none-any.whl (4.0 MB)\n",
      "     |████████████████████████████████| 4.0 MB 21.1 MB/s            \n",
      "\u001b[?25hCollecting tensorflow-text>=2.5.0\n",
      "  Downloading tensorflow_text-2.6.0-cp38-cp38-macosx_10_9_x86_64.whl (3.6 MB)\n",
      "     |████████████████████████████████| 3.6 MB 14.1 MB/s            \n",
      "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
      "  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n",
      "     |████████████████████████████████| 213 kB 13.0 MB/s            \n",
      "\u001b[?25hCollecting tensorflow-hub>=0.6.0\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "     |████████████████████████████████| 108 kB 13.7 MB/s            \n",
      "\u001b[?25hCollecting google-api-python-client>=1.6.7\n",
      "  Downloading google_api_python_client-2.27.0-py2.py3-none-any.whl (7.7 MB)\n",
      "     |████████████████████████████████| 7.7 MB 11.6 MB/s            \n",
      "\u001b[?25hCollecting oauth2client\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "     |████████████████████████████████| 98 kB 8.7 MB/s             \n",
      "\u001b[?25hCollecting sacrebleu\n",
      "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
      "     |████████████████████████████████| 90 kB 16.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages (from pandas->object-detection==0.1) (2.8.2)\n",
      "Collecting pytz>=2017.3\n",
      "  Using cached pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "Collecting absl-py>=0.2.2\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "     |████████████████████████████████| 132 kB 17.0 MB/s            \n",
      "\u001b[?25hCollecting grpcio<2,>=1.29.0\n",
      "  Using cached grpcio-1.41.0-cp38-cp38-macosx_10_10_x86_64.whl (3.9 MB)\n",
      "Collecting typing-extensions<4,>=3.7.0\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Collecting requests<3.0.0,>=2.24.0\n",
      "  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Collecting future<1.0.0,>=0.18.2\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "     |████████████████████████████████| 829 kB 14.4 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting protobuf<4,>=3.12.2\n",
      "  Downloading protobuf-3.19.0-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |████████████████████████████████| 1.0 MB 20.2 MB/s            \n",
      "\u001b[?25hCollecting pydot<2,>=1.2.0\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting pyarrow<5.0.0,>=0.15.1\n",
      "  Downloading pyarrow-4.0.1-cp38-cp38-macosx_10_13_x86_64.whl (15.7 MB)\n",
      "     |████████████████████████████████| 15.7 MB 11.6 MB/s            \n",
      "\u001b[?25hCollecting orjson<4.0\n",
      "  Downloading orjson-3.6.4-cp38-cp38-macosx_10_9_x86_64.macosx_11_0_arm64.macosx_10_9_universal2.whl (444 kB)\n",
      "     |████████████████████████████████| 444 kB 16.0 MB/s            \n",
      "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
      "  Downloading pymongo-3.12.1-cp38-cp38-macosx_10_9_x86_64.whl (395 kB)\n",
      "     |████████████████████████████████| 395 kB 13.2 MB/s            \n",
      "\u001b[?25hCollecting numpy>=1.15.4\n",
      "  Downloading numpy-1.20.3-cp38-cp38-macosx_10_9_x86_64.whl (16.0 MB)\n",
      "     |████████████████████████████████| 16.0 MB 14.6 MB/s            \n",
      "\u001b[?25hCollecting crcmod<2.0,>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "     |████████████████████████████████| 89 kB 11.3 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting avro-python3\n",
      "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting httplib2<0.20.0,>=0.8\n",
      "  Downloading httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "     |████████████████████████████████| 95 kB 3.9 MB/s             \n",
      "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "     |████████████████████████████████| 151 kB 11.1 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fastavro<2,>=0.21.4\n",
      "  Downloading fastavro-1.4.5-cp38-cp38-macosx_10_14_x86_64.whl (484 kB)\n",
      "     |████████████████████████████████| 484 kB 36.6 MB/s            \n",
      "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages (from lvis->object-detection==0.1) (4.5.3.56)\n",
      "Collecting cycler>=0.10.0\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: pyparsing>=2.4.0 in /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages (from lvis->object-detection==0.1) (2.4.7)\n",
      "Collecting kiwisolver>=1.1.0\n",
      "  Using cached kiwisolver-1.3.2-cp38-cp38-macosx_10_9_x86_64.whl (61 kB)\n",
      "Requirement already satisfied: setuptools>=18.0 in /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages (from pycocotools->object-detection==0.1) (49.2.1)\n",
      "Collecting google-api-core<3.0.0dev,>=1.21.0\n",
      "  Downloading google_api_core-2.1.1-py2.py3-none-any.whl (95 kB)\n",
      "     |████████████████████████████████| 95 kB 2.2 MB/s            \n",
      "\u001b[?25hCollecting google-auth<3.0.0dev,>=1.16.0\n",
      "  Downloading google_auth-2.3.0-py2.py3-none-any.whl (154 kB)\n",
      "     |████████████████████████████████| 154 kB 13.0 MB/s            \n",
      "\u001b[?25hCollecting google-auth-httplib2>=0.1.0\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting uritemplate<5,>=3.0.0\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting certifi\n",
      "  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "     |████████████████████████████████| 149 kB 14.8 MB/s            \n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "     |████████████████████████████████| 76 kB 8.3 MB/s             \n",
      "\u001b[?25hCollecting python-slugify\n",
      "  Downloading python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
      "Collecting urllib3\n",
      "  Using cached urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "Collecting rsa>=3.1.4\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1>=0.1.7\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting pyasn1-modules>=0.0.5\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "     |████████████████████████████████| 61 kB 10.0 MB/s            \n",
      "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.7-py3-none-any.whl (38 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "     |████████████████████████████████| 5.8 MB 6.3 MB/s            \n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Using cached tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typing-extensions<4,>=3.7.0\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting clang~=5.0\n",
      "  Using cached clang-5.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting wheel~=0.35\n",
      "  Using cached wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n",
      "Collecting six\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting numpy>=1.15.4\n",
      "  Using cached numpy-1.19.5-cp38-cp38-macosx_10_9_x86_64.whl (15.6 MB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras~=2.6\n",
      "  Using cached keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Using cached h5py-3.1.0-cp38-cp38-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "Collecting dm-tree~=0.1.1\n",
      "  Downloading dm_tree-0.1.6-cp38-cp38-macosx_10_14_x86_64.whl (95 kB)\n",
      "     |████████████████████████████████| 95 kB 8.0 MB/s             \n",
      "\u001b[?25hCollecting tabulate>=0.8.9\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting regex\n",
      "  Downloading regex-2021.10.21-cp38-cp38-macosx_10_9_x86_64.whl (288 kB)\n",
      "     |████████████████████████████████| 288 kB 10.2 MB/s            \n",
      "\u001b[?25hCollecting scikit-learn>=0.21.3\n",
      "  Using cached scikit_learn-1.0-cp38-cp38-macosx_10_13_x86_64.whl (7.9 MB)\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.0-py3-none-any.whl (17 kB)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.2.0-py3-none-any.whl (48 kB)\n",
      "     |████████████████████████████████| 48 kB 4.5 MB/s            \n",
      "\u001b[?25hCollecting importlib-resources\n",
      "  Downloading importlib_resources-5.3.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "     |████████████████████████████████| 198 kB 3.5 MB/s            \n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "     |████████████████████████████████| 288 kB 3.4 MB/s            \n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting zipp>=3.1.0\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "     |████████████████████████████████| 78 kB 2.4 MB/s            \n",
      "\u001b[?25hCollecting absl-py>=0.2.2\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "     |████████████████████████████████| 129 kB 3.3 MB/s            \n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Using legacy 'setup.py install' for object-detection, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for avro-python3, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for pycocotools, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for crcmod, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for dill, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for future, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for kaggle, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for py-cpuinfo, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for seqeval, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for clang, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for termcolor, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for wrapt, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for docopt, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for promise, since package 'wheel' is not installed.\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, rsa, requests, pyasn1-modules, oauthlib, cachetools, six, requests-oauthlib, google-auth, wheel, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, zipp, wrapt, typing-extensions, threadpoolctl, text-unidecode, termcolor, tensorflow-estimator, tensorboard, scipy, pillow, opt-einsum, kiwisolver, keras-preprocessing, keras, joblib, httplib2, h5py, googleapis-common-protos, google-pasta, gast, flatbuffers, cycler, clang, astunparse, uritemplate, typeguard, tqdm, tensorflow-metadata, tensorflow-hub, tensorflow, tabulate, scikit-learn, regex, pytz, python-slugify, promise, portalocker, matplotlib, importlib-resources, google-auth-httplib2, google-api-core, future, docopt, dm-tree, dill, Cython, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-datasets, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, pydot, pycocotools, pyarrow, py-cpuinfo, psutil, pandas, orjson, opencv-python-headless, oauth2client, kaggle, hdfs, google-api-python-client, gin-config, fastavro, crcmod, avro-python3, tf-models-official, lvis, contextlib2, apache-beam, object-detection\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.2\n",
      "    Uninstalling numpy-1.21.2:\n",
      "      Successfully uninstalled numpy-1.21.2\n",
      "    Running setup.py install for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for clang ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for promise ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for future ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for docopt ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for dill ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for seqeval ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for pycocotools ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for py-cpuinfo ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for kaggle ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for crcmod ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for avro-python3 ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for object-detection ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed Cython-0.29.24 absl-py-0.12.0 apache-beam-2.33.0 astunparse-1.6.3 avro-python3-1.9.2.1 cachetools-4.2.4 certifi-2021.10.8 charset-normalizer-2.0.7 clang-5.0 colorama-0.4.4 contextlib2-21.6.0 crcmod-1.7 cycler-0.10.0 dill-0.3.1.1 dm-tree-0.1.6 docopt-0.6.2 fastavro-1.4.5 flatbuffers-1.12 future-0.18.2 gast-0.4.0 gin-config-0.4.0 google-api-core-2.1.1 google-api-python-client-2.27.0 google-auth-2.3.0 google-auth-httplib2-0.1.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 googleapis-common-protos-1.53.0 grpcio-1.41.0 h5py-3.1.0 hdfs-2.6.0 httplib2-0.19.1 idna-3.3 importlib-resources-5.3.0 joblib-1.1.0 kaggle-1.5.12 keras-2.6.0 keras-preprocessing-1.1.2 kiwisolver-1.3.2 lvis-0.5.3 markdown-3.3.4 matplotlib-3.4.3 numpy-1.19.5 oauth2client-4.1.3 oauthlib-3.1.1 object-detection-0.1 opencv-python-headless-4.5.4.58 opt-einsum-3.3.0 orjson-3.6.4 pandas-1.3.4 pillow-8.4.0 portalocker-2.3.2 promise-2.3 protobuf-3.19.0 psutil-5.8.0 py-cpuinfo-8.0.0 pyarrow-4.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycocotools-2.0.2 pydot-1.4.2 pymongo-3.12.1 python-slugify-5.0.2 pytz-2021.3 pyyaml-6.0 regex-2021.10.21 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.7.2 sacrebleu-2.0.0 scikit-learn-1.0 scipy-1.7.1 sentencepiece-0.1.96 seqeval-1.2.2 six-1.15.0 tabulate-0.8.9 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-addons-0.14.0 tensorflow-datasets-4.4.0 tensorflow-estimator-2.6.0 tensorflow-hub-0.12.0 tensorflow-metadata-1.2.0 tensorflow-model-optimization-0.7.0 tensorflow-text-2.6.0 termcolor-1.1.0 text-unidecode-1.3 tf-models-official-2.6.0 tf-slim-1.1.0 threadpoolctl-3.0.0 tqdm-4.62.3 typeguard-2.13.0 typing-extensions-3.7.4.3 uritemplate-4.1.1 urllib3-1.26.7 werkzeug-2.0.2 wheel-0.37.0 wrapt-1.12.1 zipp-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!brew install protobuf\n",
    "!cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36308c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.8.9: /Users/jaime/deep_learning/object_detection_tf/tfod/bin/python\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2021-10-21 11:34:23.426439: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages/object_detection/builders/model_builder.py:1100: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W1021 11:34:23.842418 4442369536 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.76s\n",
      "I1021 11:34:24.180133 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.76s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.99s\n",
      "I1021 11:34:25.173058 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.99s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.42s\n",
      "I1021 11:34:25.596343 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.42s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.3s\n",
      "I1021 11:34:25.896287 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.3s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.04s\n",
      "I1021 11:34:27.941058 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.04s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I1021 11:34:27.942170 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I1021 11:34:27.966860 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
      "I1021 11:34:27.992980 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.03s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "I1021 11:34:28.015887 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
      "I1021 11:34:28.145365 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n",
      "I1021 11:34:28.264089 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n",
      "I1021 11:34:28.393807 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
      "I1021 11:34:28.532560 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
      "I1021 11:34:28.656016 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
      "I1021 11:34:28.701965 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I1021 11:34:30.568550 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I1021 11:34:30.568691 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
      "I1021 11:34:30.568758 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 3\n",
      "I1021 11:34:30.571233 4442369536 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1021 11:34:30.590718 4442369536 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1021 11:34:30.590867 4442369536 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1021 11:34:30.704173 4442369536 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1021 11:34:30.704315 4442369536 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1021 11:34:30.976833 4442369536 efficientnet_model.py:147] round_filter input=24 output=24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1021 11:34:30.976984 4442369536 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I1021 11:34:31.373178 4442369536 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I1021 11:34:31.373319 4442369536 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I1021 11:34:31.701726 4442369536 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I1021 11:34:31.701907 4442369536 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I1021 11:34:31.975491 4442369536 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I1021 11:34:31.975637 4442369536 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I1021 11:34:32.723791 4442369536 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I1021 11:34:32.723957 4442369536 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I1021 11:34:32.828570 4442369536 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I1021 11:34:32.901104 4442369536 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1021 11:34:33.092514 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I1021 11:34:33.092797 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
      "I1021 11:34:33.092941 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 4\n",
      "I1021 11:34:33.099651 4442369536 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1021 11:34:33.151885 4442369536 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1021 11:34:33.152196 4442369536 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1021 11:34:33.389926 4442369536 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1021 11:34:33.390068 4442369536 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1021 11:34:33.769372 4442369536 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1021 11:34:33.769515 4442369536 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I1021 11:34:34.019309 4442369536 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I1021 11:34:34.019457 4442369536 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I1021 11:34:34.350320 4442369536 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I1021 11:34:34.350466 4442369536 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I1021 11:34:34.686724 4442369536 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I1021 11:34:34.686867 4442369536 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I1021 11:34:35.122202 4442369536 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I1021 11:34:35.122349 4442369536 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I1021 11:34:35.323088 4442369536 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I1021 11:34:35.373198 4442369536 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1021 11:34:35.455271 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I1021 11:34:35.455448 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
      "I1021 11:34:35.455547 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 5\n",
      "I1021 11:34:35.457463 4442369536 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1021 11:34:35.473140 4442369536 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I1021 11:34:35.473279 4442369536 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1021 11:34:35.602703 4442369536 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I1021 11:34:35.602846 4442369536 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1021 11:34:35.853969 4442369536 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I1021 11:34:35.854149 4442369536 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I1021 11:34:36.103889 4442369536 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I1021 11:34:36.104038 4442369536 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I1021 11:34:36.656952 4442369536 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I1021 11:34:36.657095 4442369536 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I1021 11:34:37.356095 4442369536 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I1021 11:34:37.356251 4442369536 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I1021 11:34:37.923038 4442369536 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I1021 11:34:37.923182 4442369536 efficientnet_model.py:147] round_filter input=320 output=352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1021 11:34:38.187183 4442369536 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I1021 11:34:38.244784 4442369536 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1021 11:34:38.326009 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I1021 11:34:38.326165 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
      "I1021 11:34:38.326236 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 6\n",
      "I1021 11:34:38.328068 4442369536 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I1021 11:34:38.343927 4442369536 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I1021 11:34:38.344064 4442369536 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I1021 11:34:38.517365 4442369536 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I1021 11:34:38.517642 4442369536 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I1021 11:34:39.004347 4442369536 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I1021 11:34:39.004491 4442369536 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I1021 11:34:39.277947 4442369536 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I1021 11:34:39.278093 4442369536 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I1021 11:34:39.770467 4442369536 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I1021 11:34:39.770613 4442369536 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I1021 11:34:40.299534 4442369536 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I1021 11:34:40.299683 4442369536 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I1021 11:34:40.948045 4442369536 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I1021 11:34:40.948196 4442369536 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I1021 11:34:41.158873 4442369536 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I1021 11:34:41.210747 4442369536 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1021 11:34:41.324656 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I1021 11:34:41.324800 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
      "I1021 11:34:41.324872 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
      "I1021 11:34:41.327055 4442369536 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I1021 11:34:41.354211 4442369536 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I1021 11:34:41.354357 4442369536 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I1021 11:34:41.530616 4442369536 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I1021 11:34:41.530758 4442369536 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I1021 11:34:41.873939 4442369536 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I1021 11:34:41.874220 4442369536 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I1021 11:34:42.281732 4442369536 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I1021 11:34:42.282052 4442369536 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I1021 11:34:42.901883 4442369536 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I1021 11:34:42.902041 4442369536 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I1021 11:34:43.426004 4442369536 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I1021 11:34:43.426149 4442369536 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I1021 11:34:44.210379 4442369536 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I1021 11:34:44.210532 4442369536 efficientnet_model.py:147] round_filter input=320 output=448\n",
      "I1021 11:34:44.602094 4442369536 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
      "I1021 11:34:44.680541 4442369536 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1021 11:34:44.833967 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I1021 11:34:44.834650 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
      "I1021 11:34:44.834842 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
      "I1021 11:34:44.838212 4442369536 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I1021 11:34:44.866961 4442369536 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I1021 11:34:44.867142 4442369536 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I1021 11:34:45.146867 4442369536 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I1021 11:34:45.147013 4442369536 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I1021 11:34:45.721666 4442369536 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I1021 11:34:45.721811 4442369536 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I1021 11:34:46.217122 4442369536 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I1021 11:34:46.217265 4442369536 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I1021 11:34:46.820070 4442369536 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I1021 11:34:46.820218 4442369536 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I1021 11:34:48.200022 4442369536 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I1021 11:34:48.200234 4442369536 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I1021 11:34:49.463128 4442369536 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I1021 11:34:49.463269 4442369536 efficientnet_model.py:147] round_filter input=320 output=512\n",
      "I1021 11:34:49.845774 4442369536 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
      "I1021 11:34:49.914992 4442369536 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1021 11:34:50.030616 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I1021 11:34:50.030760 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I1021 11:34:50.030828 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
      "I1021 11:34:50.032642 4442369536 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I1021 11:34:50.049185 4442369536 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I1021 11:34:50.049323 4442369536 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I1021 11:34:50.246315 4442369536 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I1021 11:34:50.246461 4442369536 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I1021 11:34:50.768949 4442369536 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I1021 11:34:50.769096 4442369536 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I1021 11:34:51.509768 4442369536 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I1021 11:34:51.509914 4442369536 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I1021 11:34:52.188023 4442369536 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I1021 11:34:52.188165 4442369536 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I1021 11:34:52.900924 4442369536 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I1021 11:34:52.901087 4442369536 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I1021 11:34:54.034190 4442369536 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I1021 11:34:54.034368 4442369536 efficientnet_model.py:147] round_filter input=320 output=576\n",
      "I1021 11:34:54.435796 4442369536 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
      "I1021 11:34:54.513195 4442369536 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1021 11:34:54.645018 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I1021 11:34:54.645164 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I1021 11:34:54.645232 4442369536 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
      "I1021 11:34:54.647094 4442369536 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I1021 11:34:54.663486 4442369536 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I1021 11:34:54.663625 4442369536 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I1021 11:34:54.924229 4442369536 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I1021 11:34:54.924375 4442369536 efficientnet_model.py:147] round_filter input=24 output=48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1021 11:34:55.498499 4442369536 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I1021 11:34:55.498641 4442369536 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I1021 11:34:56.080433 4442369536 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I1021 11:34:56.080578 4442369536 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I1021 11:34:57.148469 4442369536 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I1021 11:34:57.148672 4442369536 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I1021 11:34:58.066895 4442369536 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I1021 11:34:58.067043 4442369536 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I1021 11:34:59.470971 4442369536 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I1021 11:34:59.471116 4442369536 efficientnet_model.py:147] round_filter input=320 output=640\n",
      "I1021 11:35:00.135932 4442369536 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
      "I1021 11:35:00.226913 4442369536 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 31.69s\n",
      "I1021 11:35:00.392795 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 31.69s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I1021 11:35:00.402854 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I1021 11:35:00.404912 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I1021 11:35:00.405403 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I1021 11:35:00.407245 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I1021 11:35:00.408915 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I1021 11:35:00.409339 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I1021 11:35:00.411075 4442369536 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 36.991s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12ce778f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\r\n",
      "----------------------------- ----------\r\n",
      "absl-py                       0.12.0\r\n",
      "apache-beam                   2.33.0\r\n",
      "appnope                       0.1.2\r\n",
      "argon2-cffi                   21.1.0\r\n",
      "astunparse                    1.6.3\r\n",
      "attrs                         21.2.0\r\n",
      "avro-python3                  1.9.2.1\r\n",
      "backcall                      0.2.0\r\n",
      "bleach                        4.1.0\r\n",
      "cachetools                    4.2.4\r\n",
      "certifi                       2021.10.8\r\n",
      "cffi                          1.15.0\r\n",
      "charset-normalizer            2.0.7\r\n",
      "clang                         5.0\r\n",
      "colorama                      0.4.4\r\n",
      "contextlib2                   21.6.0\r\n",
      "crcmod                        1.7\r\n",
      "cycler                        0.10.0\r\n",
      "Cython                        0.29.24\r\n",
      "debugpy                       1.5.1\r\n",
      "decorator                     5.1.0\r\n",
      "defusedxml                    0.7.1\r\n",
      "dill                          0.3.1.1\r\n",
      "dm-tree                       0.1.6\r\n",
      "docopt                        0.6.2\r\n",
      "entrypoints                   0.3\r\n",
      "fastavro                      1.4.5\r\n",
      "flatbuffers                   1.12\r\n",
      "future                        0.18.2\r\n",
      "gast                          0.4.0\r\n",
      "gin-config                    0.4.0\r\n",
      "google-api-core               2.1.1\r\n",
      "google-api-python-client      2.27.0\r\n",
      "google-auth                   2.3.0\r\n",
      "google-auth-httplib2          0.1.0\r\n",
      "google-auth-oauthlib          0.4.6\r\n",
      "google-pasta                  0.2.0\r\n",
      "googleapis-common-protos      1.53.0\r\n",
      "grpcio                        1.41.0\r\n",
      "h5py                          3.1.0\r\n",
      "hdfs                          2.6.0\r\n",
      "httplib2                      0.19.1\r\n",
      "idna                          3.3\r\n",
      "importlib-resources           5.3.0\r\n",
      "ipykernel                     6.4.1\r\n",
      "ipython                       7.28.0\r\n",
      "ipython-genutils              0.2.0\r\n",
      "ipywidgets                    7.6.5\r\n",
      "jedi                          0.18.0\r\n",
      "Jinja2                        3.0.2\r\n",
      "joblib                        1.1.0\r\n",
      "jsonschema                    4.1.0\r\n",
      "jupyter                       1.0.0\r\n",
      "jupyter-client                7.0.6\r\n",
      "jupyter-console               6.4.0\r\n",
      "jupyter-core                  4.8.1\r\n",
      "jupyterlab-pygments           0.1.2\r\n",
      "jupyterlab-widgets            1.0.2\r\n",
      "kaggle                        1.5.12\r\n",
      "keras                         2.6.0\r\n",
      "Keras-Preprocessing           1.1.2\r\n",
      "kiwisolver                    1.3.2\r\n",
      "labelImg                      1.8.6\r\n",
      "libs                          0.0.10\r\n",
      "lvis                          0.5.3\r\n",
      "lxml                          4.6.3\r\n",
      "Markdown                      3.3.4\r\n",
      "MarkupSafe                    2.0.1\r\n",
      "matplotlib                    3.4.3\r\n",
      "matplotlib-inline             0.1.3\r\n",
      "mistune                       0.8.4\r\n",
      "nbclient                      0.5.4\r\n",
      "nbconvert                     6.2.0\r\n",
      "nbformat                      5.1.3\r\n",
      "nest-asyncio                  1.5.1\r\n",
      "notebook                      6.4.5\r\n",
      "numpy                         1.19.5\r\n",
      "oauth2client                  4.1.3\r\n",
      "oauthlib                      3.1.1\r\n",
      "object-detection              0.1\r\n",
      "opencv-python                 4.5.3.56\r\n",
      "opencv-python-headless        4.5.4.58\r\n",
      "opt-einsum                    3.3.0\r\n",
      "orjson                        3.6.4\r\n",
      "packaging                     21.0\r\n",
      "pandas                        1.3.4\r\n",
      "pandocfilters                 1.5.0\r\n",
      "parso                         0.8.2\r\n",
      "pexpect                       4.8.0\r\n",
      "pickleshare                   0.7.5\r\n",
      "Pillow                        8.4.0\r\n",
      "pip                           21.3\r\n",
      "portalocker                   2.3.2\r\n",
      "prometheus-client             0.11.0\r\n",
      "promise                       2.3\r\n",
      "prompt-toolkit                3.0.20\r\n",
      "protobuf                      3.19.0\r\n",
      "psutil                        5.8.0\r\n",
      "ptyprocess                    0.7.0\r\n",
      "py-cpuinfo                    8.0.0\r\n",
      "pyarrow                       4.0.1\r\n",
      "pyasn1                        0.4.8\r\n",
      "pyasn1-modules                0.2.8\r\n",
      "pycocotools                   2.0.2\r\n",
      "pycparser                     2.20\r\n",
      "pydot                         1.4.2\r\n",
      "Pygments                      2.10.0\r\n",
      "pymongo                       3.12.1\r\n",
      "pyparsing                     2.4.7\r\n",
      "PyQt5                         5.15.2\r\n",
      "PyQt5-Qt5                     5.15.2\r\n",
      "PyQt5-sip                     12.9.0\r\n",
      "pyrsistent                    0.18.0\r\n",
      "python-dateutil               2.8.2\r\n",
      "python-slugify                5.0.2\r\n",
      "pytz                          2021.3\r\n",
      "PyYAML                        6.0\r\n",
      "pyzmq                         22.3.0\r\n",
      "qtconsole                     5.1.1\r\n",
      "QtPy                          1.11.2\r\n",
      "regex                         2021.10.21\r\n",
      "requests                      2.26.0\r\n",
      "requests-oauthlib             1.3.0\r\n",
      "rsa                           4.7.2\r\n",
      "sacrebleu                     2.0.0\r\n",
      "scikit-learn                  1.0\r\n",
      "scipy                         1.7.1\r\n",
      "Send2Trash                    1.8.0\r\n",
      "sentencepiece                 0.1.96\r\n",
      "seqeval                       1.2.2\r\n",
      "setuptools                    49.2.1\r\n",
      "six                           1.15.0\r\n",
      "tabulate                      0.8.9\r\n",
      "tensorboard                   2.7.0\r\n",
      "tensorboard-data-server       0.6.1\r\n",
      "tensorboard-plugin-wit        1.8.0\r\n",
      "tensorflow                    2.6.0\r\n",
      "tensorflow-addons             0.14.0\r\n",
      "tensorflow-datasets           4.4.0\r\n",
      "tensorflow-estimator          2.6.0\r\n",
      "tensorflow-hub                0.12.0\r\n",
      "tensorflow-metadata           1.2.0\r\n",
      "tensorflow-model-optimization 0.7.0\r\n",
      "tensorflow-text               2.6.0\r\n",
      "termcolor                     1.1.0\r\n",
      "terminado                     0.12.1\r\n",
      "testpath                      0.5.0\r\n",
      "text-unidecode                1.3\r\n",
      "tf-models-official            2.6.0\r\n",
      "tf-slim                       1.1.0\r\n",
      "threadpoolctl                 3.0.0\r\n",
      "tornado                       6.1\r\n",
      "tqdm                          4.62.3\r\n",
      "traitlets                     5.1.0\r\n",
      "typeguard                     2.13.0\r\n",
      "typing-extensions             3.7.4.3\r\n",
      "uritemplate                   4.1.1\r\n",
      "urllib3                       1.26.7\r\n",
      "wcwidth                       0.2.5\r\n",
      "webencodings                  0.5.1\r\n",
      "Werkzeug                      2.0.2\r\n",
      "wheel                         0.37.0\r\n",
      "widgetsnbextension            3.5.1\r\n",
      "wrapt                         1.12.1\r\n",
      "zipp                          3.6.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15b5d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "550ec9bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Homebrew...\n",
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updated Homebrew!\u001b[0m\n",
      "Updated 2 taps (homebrew/core and homebrew/cask).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNew Formulae\u001b[0m\n",
      "jellyfish\n",
      "\u001b[34m==>\u001b[0m \u001b[1mUpdated Formulae\u001b[0m\n",
      "Updated 27 formulae.\n",
      "\u001b[34m==>\u001b[0m \u001b[1mUpdated Casks\u001b[0m\n",
      "Updated 5 casks.\n",
      "\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libunistring/manifests/0.9.10\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libunistring/blobs/sha256:5d336\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libidn2/manifests/2.3.2\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libidn2/blobs/sha256:d21350f576\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/wget/manifests/1.21.2\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/wget/blobs/sha256:7a8e6512e0890\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling dependencies for wget: \u001b[32mlibunistring\u001b[39m and \u001b[32mlibidn2\u001b[39m\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling wget dependency: \u001b[32mlibunistring\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libunistring--0.9.10.big_sur.bottle.tar.gz\u001b[0m\n",
      "🍺  /usr/local/Cellar/libunistring/0.9.10: 55 files, 4.5MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling wget dependency: \u001b[32mlibidn2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libidn2--2.3.2.big_sur.bottle.tar.gz\u001b[0m\n",
      "🍺  /usr/local/Cellar/libidn2/2.3.2: 77 files, 846.8KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling \u001b[32mwget\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring wget--1.21.2.big_sur.bottle.tar.gz\u001b[0m\n",
      "🍺  /usr/local/Cellar/wget/1.21.2: 89 files, 4.2MB\n"
     ]
    }
   ],
   "source": [
    "!brew install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a65c5a",
   "metadata": {},
   "source": [
    "`tar -zxvf`\n",
    "- `z` means (un)z̲ip.\n",
    "- `x` means ex̲tract files from the archive.\n",
    "- `v` means print the filenames v̲erbosely.\n",
    "- `f` means the following argument is a f̱ilename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fc08f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-21 17:27:04--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      "Resolviendo download.tensorflow.org (download.tensorflow.org)... 142.250.200.48\n",
      "Conectando con download.tensorflow.org (download.tensorflow.org)[142.250.200.48]:80... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 20515344 (20M) [application/x-tar]\n",
      "Grabando a: «ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz»\n",
      "\n",
      "ssd_mobilenet_v2_fp 100%[===================>]  19,56M  12,5MB/s    en 1,6s    \n",
      "\n",
      "2021-10-21 17:27:06 (12,5 MB/s) - «ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz» guardado [20515344/20515344]\n",
      "\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "if os.name == 'posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdc91e9",
   "metadata": {},
   "source": [
    "# 2. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ee4d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'tongueout', 'id':1},\n",
    "          {'name':'wink', 'id':2},\n",
    "          {'name':'smile', 'id':3},\n",
    "          {'name':'surprise', 'id':4}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4a6e196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensorflow/workspace/annotations/label_map.pbtxt'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files['LABELMAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cab6f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b103ad3",
   "metadata": {},
   "source": [
    "Eventually we're getting a file `label_map.pbtxt` like this one:\n",
    "\n",
    "    item {\n",
    "        name:'tongueout'\n",
    "        id:1\n",
    "    }\n",
    "    item { \n",
    "        name:'wink'\n",
    "        id:2\n",
    "    }\n",
    "    item { \n",
    "        name:'smile'\n",
    "        id:3\n",
    "    }\n",
    "    item { \n",
    "        name:'surprise'\n",
    "        id:4\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b98d0",
   "metadata": {},
   "source": [
    "# 3. Create TF records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44b26e1",
   "metadata": {},
   "source": [
    "`TFRecords` is a binary format to storing data. It helps to speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4c17aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clonando en 'Tensorflow/scripts'...\n",
      "remote: Enumerating objects: 3, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
      "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
      "Recibiendo objetos: 100% (3/3), listo.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c5c4797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensorflow/scripts/generate_tfrecord.py'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files['TF_RECORD_SCRIPT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36274769",
   "metadata": {},
   "source": [
    "    usage: generate_tfrecord.py [-h] [-x XML_DIR] [-l LABELS_PATH] [-o OUTPUT_PATH] [-i IMAGE_DIR] [-c CSV_PATH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a89f76dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be92e4a3",
   "metadata": {},
   "source": [
    "# 4. Copy Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b771081",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a8009",
   "metadata": {},
   "source": [
    "# 5. Update Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1118924",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8ba59af",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dec275e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files['PIPELINE_CONFIG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3be2ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': ssd {\n",
       "   num_classes: 90\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 320\n",
       "       width: 320\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "     depth_multiplier: 1.0\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 3.9999998989515007e-05\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         random_normal_initializer {\n",
       "           mean: 0.0\n",
       "           stddev: 0.009999999776482582\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.996999979019165\n",
       "         scale: true\n",
       "         epsilon: 0.0010000000474974513\n",
       "       }\n",
       "     }\n",
       "     use_depthwise: true\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       additional_layer_depth: 128\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10.0\n",
       "       x_scale: 10.0\n",
       "       height_scale: 5.0\n",
       "       width_scale: 5.0\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 3.9999998989515007e-05\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0.0\n",
       "             stddev: 0.009999999776482582\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.996999979019165\n",
       "           scale: true\n",
       "           epsilon: 0.0010000000474974513\n",
       "         }\n",
       "       }\n",
       "       depth: 128\n",
       "       num_layers_before_predictor: 4\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.599999904632568\n",
       "       share_prediction_tower: true\n",
       "       use_depthwise: true\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4.0\n",
       "       aspect_ratios: 1.0\n",
       "       aspect_ratios: 2.0\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 9.99999993922529e-09\n",
       "       iou_threshold: 0.6000000238418579\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "       use_static_shapes: false\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2.0\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1.0\n",
       "     localization_weight: 1.0\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   inplace_batchnorm_update: true\n",
       "   freeze_batchnorm: false\n",
       " },\n",
       " 'train_config': batch_size: 128\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0.0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3.0\n",
       "     min_area: 0.75\n",
       "     max_area: 1.0\n",
       "     overlap_thresh: 0.0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.07999999821186066\n",
       "         total_steps: 50000\n",
       "         warmup_learning_rate: 0.026666000485420227\n",
       "         warmup_steps: 1000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.8999999761581421\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
       " num_steps: 50000\n",
       " startup_delay_steps: 0.0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"classification\"\n",
       " fine_tune_checkpoint_version: V2,\n",
       " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " },\n",
       " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false,\n",
       " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "edfffb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77ee0efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model {\n",
       "  ssd {\n",
       "    num_classes: 90\n",
       "    image_resizer {\n",
       "      fixed_shape_resizer {\n",
       "        height: 320\n",
       "        width: 320\n",
       "      }\n",
       "    }\n",
       "    feature_extractor {\n",
       "      type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "      depth_multiplier: 1.0\n",
       "      min_depth: 16\n",
       "      conv_hyperparams {\n",
       "        regularizer {\n",
       "          l2_regularizer {\n",
       "            weight: 3.9999998989515007e-05\n",
       "          }\n",
       "        }\n",
       "        initializer {\n",
       "          random_normal_initializer {\n",
       "            mean: 0.0\n",
       "            stddev: 0.009999999776482582\n",
       "          }\n",
       "        }\n",
       "        activation: RELU_6\n",
       "        batch_norm {\n",
       "          decay: 0.996999979019165\n",
       "          scale: true\n",
       "          epsilon: 0.0010000000474974513\n",
       "        }\n",
       "      }\n",
       "      use_depthwise: true\n",
       "      override_base_feature_extractor_hyperparams: true\n",
       "      fpn {\n",
       "        min_level: 3\n",
       "        max_level: 7\n",
       "        additional_layer_depth: 128\n",
       "      }\n",
       "    }\n",
       "    box_coder {\n",
       "      faster_rcnn_box_coder {\n",
       "        y_scale: 10.0\n",
       "        x_scale: 10.0\n",
       "        height_scale: 5.0\n",
       "        width_scale: 5.0\n",
       "      }\n",
       "    }\n",
       "    matcher {\n",
       "      argmax_matcher {\n",
       "        matched_threshold: 0.5\n",
       "        unmatched_threshold: 0.5\n",
       "        ignore_thresholds: false\n",
       "        negatives_lower_than_unmatched: true\n",
       "        force_match_for_each_row: true\n",
       "        use_matmul_gather: true\n",
       "      }\n",
       "    }\n",
       "    similarity_calculator {\n",
       "      iou_similarity {\n",
       "      }\n",
       "    }\n",
       "    box_predictor {\n",
       "      weight_shared_convolutional_box_predictor {\n",
       "        conv_hyperparams {\n",
       "          regularizer {\n",
       "            l2_regularizer {\n",
       "              weight: 3.9999998989515007e-05\n",
       "            }\n",
       "          }\n",
       "          initializer {\n",
       "            random_normal_initializer {\n",
       "              mean: 0.0\n",
       "              stddev: 0.009999999776482582\n",
       "            }\n",
       "          }\n",
       "          activation: RELU_6\n",
       "          batch_norm {\n",
       "            decay: 0.996999979019165\n",
       "            scale: true\n",
       "            epsilon: 0.0010000000474974513\n",
       "          }\n",
       "        }\n",
       "        depth: 128\n",
       "        num_layers_before_predictor: 4\n",
       "        kernel_size: 3\n",
       "        class_prediction_bias_init: -4.599999904632568\n",
       "        share_prediction_tower: true\n",
       "        use_depthwise: true\n",
       "      }\n",
       "    }\n",
       "    anchor_generator {\n",
       "      multiscale_anchor_generator {\n",
       "        min_level: 3\n",
       "        max_level: 7\n",
       "        anchor_scale: 4.0\n",
       "        aspect_ratios: 1.0\n",
       "        aspect_ratios: 2.0\n",
       "        aspect_ratios: 0.5\n",
       "        scales_per_octave: 2\n",
       "      }\n",
       "    }\n",
       "    post_processing {\n",
       "      batch_non_max_suppression {\n",
       "        score_threshold: 9.99999993922529e-09\n",
       "        iou_threshold: 0.6000000238418579\n",
       "        max_detections_per_class: 100\n",
       "        max_total_detections: 100\n",
       "        use_static_shapes: false\n",
       "      }\n",
       "      score_converter: SIGMOID\n",
       "    }\n",
       "    normalize_loss_by_num_matches: true\n",
       "    loss {\n",
       "      localization_loss {\n",
       "        weighted_smooth_l1 {\n",
       "        }\n",
       "      }\n",
       "      classification_loss {\n",
       "        weighted_sigmoid_focal {\n",
       "          gamma: 2.0\n",
       "          alpha: 0.25\n",
       "        }\n",
       "      }\n",
       "      classification_weight: 1.0\n",
       "      localization_weight: 1.0\n",
       "    }\n",
       "    encode_background_as_zeros: true\n",
       "    normalize_loc_loss_by_codesize: true\n",
       "    inplace_batchnorm_update: true\n",
       "    freeze_batchnorm: false\n",
       "  }\n",
       "}\n",
       "train_config {\n",
       "  batch_size: 128\n",
       "  data_augmentation_options {\n",
       "    random_horizontal_flip {\n",
       "    }\n",
       "  }\n",
       "  data_augmentation_options {\n",
       "    random_crop_image {\n",
       "      min_object_covered: 0.0\n",
       "      min_aspect_ratio: 0.75\n",
       "      max_aspect_ratio: 3.0\n",
       "      min_area: 0.75\n",
       "      max_area: 1.0\n",
       "      overlap_thresh: 0.0\n",
       "    }\n",
       "  }\n",
       "  sync_replicas: true\n",
       "  optimizer {\n",
       "    momentum_optimizer {\n",
       "      learning_rate {\n",
       "        cosine_decay_learning_rate {\n",
       "          learning_rate_base: 0.07999999821186066\n",
       "          total_steps: 50000\n",
       "          warmup_learning_rate: 0.026666000485420227\n",
       "          warmup_steps: 1000\n",
       "        }\n",
       "      }\n",
       "      momentum_optimizer_value: 0.8999999761581421\n",
       "    }\n",
       "    use_moving_average: false\n",
       "  }\n",
       "  fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
       "  num_steps: 50000\n",
       "  startup_delay_steps: 0.0\n",
       "  replicas_to_aggregate: 8\n",
       "  max_number_of_boxes: 100\n",
       "  unpad_groundtruth_tensors: false\n",
       "  fine_tune_checkpoint_type: \"classification\"\n",
       "  fine_tune_checkpoint_version: V2\n",
       "}\n",
       "train_input_reader {\n",
       "  label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       "  tf_record_input_reader {\n",
       "    input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       "  }\n",
       "}\n",
       "eval_config {\n",
       "  metrics_set: \"coco_detection_metrics\"\n",
       "  use_moving_averages: false\n",
       "}\n",
       "eval_input_reader {\n",
       "  label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       "  shuffle: false\n",
       "  num_epochs: 1\n",
       "  tf_record_input_reader {\n",
       "    input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e20b0b",
   "metadata": {},
   "source": [
    "Let's change some hyperparameters like the number of classes `num_classes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e4f9e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b88bec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model {\n",
       "  ssd {\n",
       "    num_classes: 4\n",
       "    image_resizer {\n",
       "      fixed_shape_resizer {\n",
       "        height: 320\n",
       "        width: 320\n",
       "      }\n",
       "    }\n",
       "    feature_extractor {\n",
       "      type: \"ssd_mobilenet_v2_fpn_keras\"\n",
       "      depth_multiplier: 1.0\n",
       "      min_depth: 16\n",
       "      conv_hyperparams {\n",
       "        regularizer {\n",
       "          l2_regularizer {\n",
       "            weight: 3.9999998989515007e-05\n",
       "          }\n",
       "        }\n",
       "        initializer {\n",
       "          random_normal_initializer {\n",
       "            mean: 0.0\n",
       "            stddev: 0.009999999776482582\n",
       "          }\n",
       "        }\n",
       "        activation: RELU_6\n",
       "        batch_norm {\n",
       "          decay: 0.996999979019165\n",
       "          scale: true\n",
       "          epsilon: 0.0010000000474974513\n",
       "        }\n",
       "      }\n",
       "      use_depthwise: true\n",
       "      override_base_feature_extractor_hyperparams: true\n",
       "      fpn {\n",
       "        min_level: 3\n",
       "        max_level: 7\n",
       "        additional_layer_depth: 128\n",
       "      }\n",
       "    }\n",
       "    box_coder {\n",
       "      faster_rcnn_box_coder {\n",
       "        y_scale: 10.0\n",
       "        x_scale: 10.0\n",
       "        height_scale: 5.0\n",
       "        width_scale: 5.0\n",
       "      }\n",
       "    }\n",
       "    matcher {\n",
       "      argmax_matcher {\n",
       "        matched_threshold: 0.5\n",
       "        unmatched_threshold: 0.5\n",
       "        ignore_thresholds: false\n",
       "        negatives_lower_than_unmatched: true\n",
       "        force_match_for_each_row: true\n",
       "        use_matmul_gather: true\n",
       "      }\n",
       "    }\n",
       "    similarity_calculator {\n",
       "      iou_similarity {\n",
       "      }\n",
       "    }\n",
       "    box_predictor {\n",
       "      weight_shared_convolutional_box_predictor {\n",
       "        conv_hyperparams {\n",
       "          regularizer {\n",
       "            l2_regularizer {\n",
       "              weight: 3.9999998989515007e-05\n",
       "            }\n",
       "          }\n",
       "          initializer {\n",
       "            random_normal_initializer {\n",
       "              mean: 0.0\n",
       "              stddev: 0.009999999776482582\n",
       "            }\n",
       "          }\n",
       "          activation: RELU_6\n",
       "          batch_norm {\n",
       "            decay: 0.996999979019165\n",
       "            scale: true\n",
       "            epsilon: 0.0010000000474974513\n",
       "          }\n",
       "        }\n",
       "        depth: 128\n",
       "        num_layers_before_predictor: 4\n",
       "        kernel_size: 3\n",
       "        class_prediction_bias_init: -4.599999904632568\n",
       "        share_prediction_tower: true\n",
       "        use_depthwise: true\n",
       "      }\n",
       "    }\n",
       "    anchor_generator {\n",
       "      multiscale_anchor_generator {\n",
       "        min_level: 3\n",
       "        max_level: 7\n",
       "        anchor_scale: 4.0\n",
       "        aspect_ratios: 1.0\n",
       "        aspect_ratios: 2.0\n",
       "        aspect_ratios: 0.5\n",
       "        scales_per_octave: 2\n",
       "      }\n",
       "    }\n",
       "    post_processing {\n",
       "      batch_non_max_suppression {\n",
       "        score_threshold: 9.99999993922529e-09\n",
       "        iou_threshold: 0.6000000238418579\n",
       "        max_detections_per_class: 100\n",
       "        max_total_detections: 100\n",
       "        use_static_shapes: false\n",
       "      }\n",
       "      score_converter: SIGMOID\n",
       "    }\n",
       "    normalize_loss_by_num_matches: true\n",
       "    loss {\n",
       "      localization_loss {\n",
       "        weighted_smooth_l1 {\n",
       "        }\n",
       "      }\n",
       "      classification_loss {\n",
       "        weighted_sigmoid_focal {\n",
       "          gamma: 2.0\n",
       "          alpha: 0.25\n",
       "        }\n",
       "      }\n",
       "      classification_weight: 1.0\n",
       "      localization_weight: 1.0\n",
       "    }\n",
       "    encode_background_as_zeros: true\n",
       "    normalize_loc_loss_by_codesize: true\n",
       "    inplace_batchnorm_update: true\n",
       "    freeze_batchnorm: false\n",
       "  }\n",
       "}\n",
       "train_config {\n",
       "  batch_size: 4\n",
       "  data_augmentation_options {\n",
       "    random_horizontal_flip {\n",
       "    }\n",
       "  }\n",
       "  data_augmentation_options {\n",
       "    random_crop_image {\n",
       "      min_object_covered: 0.0\n",
       "      min_aspect_ratio: 0.75\n",
       "      max_aspect_ratio: 3.0\n",
       "      min_area: 0.75\n",
       "      max_area: 1.0\n",
       "      overlap_thresh: 0.0\n",
       "    }\n",
       "  }\n",
       "  sync_replicas: true\n",
       "  optimizer {\n",
       "    momentum_optimizer {\n",
       "      learning_rate {\n",
       "        cosine_decay_learning_rate {\n",
       "          learning_rate_base: 0.07999999821186066\n",
       "          total_steps: 50000\n",
       "          warmup_learning_rate: 0.026666000485420227\n",
       "          warmup_steps: 1000\n",
       "        }\n",
       "      }\n",
       "      momentum_optimizer_value: 0.8999999761581421\n",
       "    }\n",
       "    use_moving_average: false\n",
       "  }\n",
       "  fine_tune_checkpoint: \"Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
       "  num_steps: 50000\n",
       "  startup_delay_steps: 0.0\n",
       "  replicas_to_aggregate: 8\n",
       "  max_number_of_boxes: 100\n",
       "  unpad_groundtruth_tensors: false\n",
       "  fine_tune_checkpoint_type: \"detection\"\n",
       "  fine_tune_checkpoint_version: V2\n",
       "}\n",
       "train_input_reader {\n",
       "  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
       "  tf_record_input_reader {\n",
       "    input_path: \"Tensorflow/workspace/annotations/train.record\"\n",
       "  }\n",
       "}\n",
       "eval_config {\n",
       "  metrics_set: \"coco_detection_metrics\"\n",
       "  use_moving_averages: false\n",
       "}\n",
       "eval_input_reader {\n",
       "  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
       "  shuffle: false\n",
       "  num_epochs: 1\n",
       "  tf_record_input_reader {\n",
       "    input_path: \"Tensorflow/workspace/annotations/test.record\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ea655be",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1626b043",
   "metadata": {},
   "source": [
    "# 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f1bbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "682e7332",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\"\\\n",
    ".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'], files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00e51387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "823d4931",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-22 10:50:43.928374: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W1022 10:50:43.935950 4615876096 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I1022 10:50:43.984852 4615876096 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
      "I1022 10:50:44.117370 4615876096 config_util.py:552] Maybe overwriting train_steps: 2000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1022 10:50:44.117628 4615876096 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages/object_detection/model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W1022 10:50:44.346682 4615876096 deprecation.py:339] From /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages/object_detection/model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "I1022 10:50:44.366208 4615876096 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "I1022 10:50:44.367350 4615876096 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I1022 10:50:44.367799 4615876096 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1022 10:50:44.367980 4615876096 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W1022 10:50:44.393978 4615876096 deprecation.py:339] From /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1022 10:50:44.519567 4615876096 deprecation.py:339] From /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W1022 10:50:55.848376 4615876096 deprecation.py:339] From /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W1022 10:51:00.544378 4615876096 deprecation.py:339] From /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1022 10:51:02.960176 4615876096 deprecation.py:339] From /Users/jaime/deep_learning/object_detection_tf/tfod/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2021-10-22 10:51:06.200164: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-22 10:51:07.605807: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d34ac9",
   "metadata": {},
   "source": [
    "# 7. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0606937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_confi_path={} --checkpoint_dir={}\"\\\n",
    ".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'], files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
